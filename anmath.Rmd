---
title: "Mini-project 2"
author: "Ankit Mathur & Nitesh Jaswal"
date: "3/17/2019"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(broom)
library(arm)
cb_palette = c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r}
WTHH_full = read_csv("DFP_WTHH_release.csv")
WTHH = WTHH_full[c("presvote16post", "house3", "weight_DFP", "M4A", "GREENJOB", "WEALTH", "MARLEG", "ICE", "GUNS", "POP_1", "POP_2", "POP_3")]
```

```{r}
# WTHH$grp <- ifelse(WTHH$presvote16post==1 & WTHH$house3==1, "Loyal Democrats", ifelse(WTHH$presvote16post==2 & WTHH$house3==2, "Loyal Republicans", ifelse(!(WTHH$presvote16post %in% c(7,NA)), "Swing voters", NA)))
WTHH$grp <- ifelse(WTHH$presvote16post==1 & WTHH$house3==1, "Loyal Democrats", ifelse(WTHH$presvote16post==2 & WTHH$house3==2, "Loyal Republicans", ifelse(!is.na(WTHH$presvote16post), "Swing voters", NA)))

WTHH$swing_bhv <- ifelse(WTHH$grp=="Swing voters", ifelse(WTHH$house3==1, "Switch to D", ifelse(WTHH$house3==2, "Switch to R", "Others")), NA)

# cols <- c("presvote16post", "house3", "M4A", "GREENJOB", "WEALTH", "MARLEG", "ICE", "GUNS", "POP_1", "POP_2", "POP_3", "grp", "swing_bhv")
# WTHH[cols] <- lapply(WTHH[cols], factor)
```

# Solution 2:
```{r}
WTHH.long = gather(WTHH, key="issue", value="response",
                   c("M4A", "GREENJOB", "WEALTH", "MARLEG", "ICE", "GUNS"))
cols <- c("issue", "response")
WTHH.long[cols] <- lapply(WTHH.long[cols], factor)
WTHH.long <- WTHH.long[c("issue", "response", "grp", "weight_DFP")]
WTHH.long <- WTHH.long[!is.na(WTHH.long$response) & !is.na(WTHH.long$grp),]
```

```{r}
ggplot(WTHH.long, aes(x=response)) + stat_count(aes(fill=grp, weight=weight_DFP)) +
  facet_wrap(~issue) + scale_fill_manual(values=cb_palette) +
  labs(fill="Voter group", caption="1:Strongly support 2:Somewhat support 3:Neutral 4:Somewhat oppose \n5:Strongly oppose 6:Not sure") +
  ggtitle("Distribution of Voter groups by Issue") +
  xlab("Response") + ylab("Number of voters") +
  theme_bw()
```
With the exception of immigration issue (ICE), **Swing voters** tend to share *similar* opinions with **Loyal Democrats** across all of the remaining five issues. Interestingly, both these cohorts voted in favor of all five issues with a majority of voters choosing the *Strongly support* option.  
Having said this, an equivalent number of **Swing voters** chose *Strongly support* and *Strongly oppose* on the Medicare for all (M4A) issue, thereby showcasing a slightly different opinion than the **Loyal Democrats**.  
As for the immigration issue, while **Loyal Democrats** do not seem to have any coherent opinion, both **Loyal Democrats** and **Swing voters** cohorts voted against the defunding of ICE with a majority of them choosing the *Strongly oppose* option.


# Solution 3:
```{r}
WTHH$swing_voter = ifelse(WTHH$grp=="Swing voters", 1, ifelse(is.na(WTHH$grp), NA, 0))
WTHH.issue = WTHH[c("GREENJOB", "GUNS", "ICE", "M4A", "MARLEG", "WEALTH", "weight_DFP", "swing_voter")]
```

```{r}
WTHH.issue <- WTHH.issue[rowSums(WTHH.issue[,c(1,2,3,4,5,6)] == 6) == 0,]
WTHH.issue <- WTHH.issue[complete.cases(WTHH.issue),]
```

```{r}
WTHH.issue.long = gather(WTHH.issue, key="issue", value="response",
                   c("M4A", "GREENJOB", "WEALTH", "MARLEG", "ICE", "GUNS"))
ggplot(WTHH.issue.long, aes(x=response, y=swing_voter)) + geom_point(alpha=0.4) +
  geom_jitter(height=0.1, width=0.25) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  facet_wrap(~issue) +
  labs(caption="1:Strongly support 2:Somewhat support 3:Neutral 4:Somewhat oppose 5:Strongly oppose") +
  ggtitle("Logistic regression fits for odds of Swing Voter by Issue") +
  xlab("Response") + ylab("Probability of Swing voter") +
  theme_bw()
```
The plots above showcase how the predicted probability of a registered voter being a swing voter varies with responses to each of the six issues. With the exception of GREENJOB and MARLEG, all the other fitted lines are fairly flat suggesting that we include just these two issues in our final model.  
However, just to be sure, we did explicitly fit a logistic regression model including all six issue variables without interaction and looked at the coefficients for each of these issues (see appendix). As expected, the coefficients for all issues, except GREENJOB and MARLEG, turned out to be close to zero.  
Hence, in our final model, we will focus only on these two issues. Furthermore, for the sake of simplicity more than anything else, we will avoid including any interactions between our predictors.  
Finally, let us fit a model to predict swing voters using GREENJOB and MARLEG issues:
```{r}
WTHH.issue.logit <- glm(swing_voter ~ GREENJOB + MARLEG, weights=weight_DFP, family="quasibinomial", data=WTHH.issue)
display(WTHH.issue.logit)
```
Interpreting the model above, we get:
$$
\textrm{logit[P(Swing voter)]} =  - 1.75 + 0.25 \times \textrm{GREENJOB} - 0.19 \times \textrm{MARLEG}
$$
Using the "divide by 4" rule, we can say that:  
• As per our model, keeping the opinion on MARLEG constant and moving one level closer to opposing the GREENJOB issue *increases* the probability of swing voter by 6.25%  
• Similarly, keeping the opinion on GREENJOB constant and moving one level closer to opposing the MARLEG issue *decreases* the model probabilty by 4.75%  

Now, let's visualize this model.
```{r}
issue.predict.grid = expand.grid(MARLEG = seq(1, 5, 1), GREENJOB = seq(1, 5, 1))
issue.pred = predict(WTHH.issue.logit, type = "response", newdata = issue.predict.grid)
issue.pred.df = data.frame(issue.predict.grid, swing.prob = as.vector(issue.pred))

ggplot(issue.pred.df, aes(x = MARLEG, y = swing.prob, group = factor(GREENJOB), color = factor(GREENJOB))) +
  geom_line(size=1) + xlab("MARLEG Response") + ylab("Probability of Swing voter") +
  labs(color = "GREENJOB \n Response", caption="1:Strongly support 2:Somewhat support 3:Neutral 4:Somewhat oppose 5:Strongly oppose") +
  theme_bw() + scale_color_manual(values = cb_palette)
```


```{r}
# Raster 
ggplot(issue.pred.df, aes(x = MARLEG, y = GREENJOB, z = swing.prob)) + geom_raster(aes(fill = swing.prob))  + coord_fixed() + scale_fill_distiller(palette = "RdYlBu") + theme_bw() + labs(title="Predicted probability plot for a given response \non issue variables", fill = "Predicted \nProbability", caption="1:Strongly support 2:Somewhat support 3:Neutral 4:Somewhat oppose \n5:Strongly oppose 6:Not sure" )
```
In the above plots, it can be clearly visualized that keeping the opinion on GREENJOB constant and moving towards opposing the MARLEG issue *decreases* the model probabilty of being a swing voter. Furthermore, for a given opinion on MARLEG, the more a voter opposes GREENJOB, higher are the chances of him/her being a swing voter.  

Moving on to *populism* variables, let's do a faceted plot (as before) to get a feel of how the odds of swing voter vary with each populism variable.

```{r}
WTHH.pop = WTHH[c("POP_1", "POP_2", "POP_3", "weight_DFP", "swing_voter")]
```

```{r}
WTHH.pop <- WTHH.pop[rowSums(WTHH.pop[,c(1,2,3)] == 6) == 0,]
WTHH.pop <- WTHH.pop[complete.cases(WTHH.pop),]
```

```{r}
WTHH.pop.long = gather(WTHH.pop, key="populism", value="response",
                   c("POP_1", "POP_2", "POP_3"))
ggplot(WTHH.pop.long, aes(x=response, y=swing_voter)) + geom_point(alpha=0.4) +
  geom_jitter(height=0.1, width=0.25) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  facet_wrap(~populism) +
  labs(caption="1:Strongly support 2:Somewhat support 3:Neutral 4:Somewhat oppose 5:Strongly oppose") +
  ggtitle("Logistic regression fits for odds of Swing Voter by Populism") +
  xlab("Response") + ylab("Probability of Swing voter") +
  theme_bw()
```
The slope of the fitted lines decrease as we move from *POP_1* to *POP_2* ultimately flattening out as we reach *POP_3*. As before, just for our satisfaction, we looked at the slopes for each of these populism variables by explicitly fitting a logistic regression model for predicting the swing voters and observed that the coefficients for *POP_2* and *POP_3* variables did not turn out to be significant enough (see appendix).  
Hence, let us fit our second model based on just the *POP_1* populism variable:
```{r}
WTHH.pop.logit <- glm(swing_voter ~ POP_1, weights=weight_DFP, family="quasibinomial", data=WTHH.pop)
display(WTHH.pop.logit)
```

We interpret the coefficients above as representing to odds of a registered voter being a swing voter as below:
$$
\textrm{logit[P(Swing voter)]} = - 0.79 - 0.28 \times{POP_1}
$$
Again, as per the "divide by 4" rule, we can say that an increment of one degree of disagreement with the sentiment shared by *POP_1* variable decreases the probability of swing voter by 7%.  

Visualizing this model we get:
```{r}
pop.predict.grid = expand.grid(POP_1 = seq(1, 5, 1))
pop.pred = predict(WTHH.pop.logit, type = "response", newdata = pop.predict.grid)
pop.pred.df = data.frame(pop.predict.grid, swing.prob = as.vector(pop.pred))
ggplot(pop.pred.df, aes(x = POP_1, y = swing.prob)) +
  geom_line(size=1) + xlab("POP_1 Response") + ylab("Probability of Swing voter") +
  labs(caption="1:Strongly agree 2:Somewhat agree 3:Neutral 4:Somewhat disagree 5:Strongly disagree", title="Logistic regression fit for odds of swing voter") +
  theme_bw() + scale_color_manual(values = cb_palette)
```

While the training set classification error for the **issue** model is 13.8%, for the **populism** model it is XXX suggesting that **populism** variables are much better at predicting the odds of swing voters.

```{r}
issue.predict.grid = expand.grid(MARLEG = seq(1, 5, 1), GREENJOB = seq(1, 5, 1))
issue.pred = predict(WTHH.issue.logit, type = "response", newdata = issue.predict.grid)
issue.pred.df = data.frame(issue.predict.grid, swing.prob = as.vector(issue.pred/max(issue.pred)))
ggplot(issue.pred.df, aes(x = MARLEG, y = swing.prob, group = GREENJOB, color = GREENJOB)) + geom_line() + xlab("MARLEG Response") + ylab("Probability of Swing voter") + labs(color = "GREENJOB \n Response") + theme_bw() + scale_color_continuous(low = "#E69F00", high = "#CC79A7")
```

# Appendix

```{r}
WTHH.issue.logit1 <- glm(swing_voter ~ GREENJOB + GUNS + ICE + M4A + MARLEG + WEALTH, weights=weight_DFP, family="quasibinomial", data=WTHH.issue)
display(WTHH.issue.logit1)
```

```{r}
WTHH.issue.logit3 <- glm(swing_voter ~ GREENJOB * GUNS * ICE * M4A * MARLEG * WEALTH, weights=weight_DFP, family="quasibinomial", data=WTHH.issue)
display(WTHH.issue.logit3)
```

```{r}
WTHH.issue.logit.df <- WTHH.issue
WTHH.issue.logit.df$.fitted <- fitted.values(WTHH.issue.logit)
WTHH.issue.logit.df$.resid <- residuals(WTHH.issue.logit, type="response")
WTHH.issue.logit.df$.pred <- 1 * (WTHH.issue.logit.df$.fitted > max(WTHH.issue.logit.df$.fitted)/1)
Correct <- (WTHH.issue.logit.df$swing_voter == WTHH.issue.logit.df$.pred)
1 - (sum(Correct) / nrow(WTHH.issue.logit.df))
summary(factor(WTHH.issue.logit.df$swing_voter))
```

```{r residuals for issue}
ggplot(WTHH.issue.logit.df, aes(x=GREENJOB, y=.resid)) + geom_point(alpha=0.4) +
  geom_jitter(height=0.1, width=0.25) + geom_smooth(method = "loess", method.args = list(degree = 1)) +
  xlab("Response") + ylab("Residuals") + ggtitle("Residual plot for GREENJOB")
ggplot(WTHH.issue.logit.df, aes(x=MARLEG, y=.resid)) + geom_point(alpha=0.4) +
  geom_jitter(height=0.1, width=0.25) + geom_smooth(method = "loess", method.args = list(degree = 1)) +
  xlab("Response") + ylab("Residuals") + ggtitle("Residual plot for MARLEG")
```

```{r}
WTHH.pop.logit1 <- glm(swing_voter ~ POP_1 * POP_2 * POP_3, weights=weight_DFP, family="quasibinomial", data=WTHH.pop)
display(WTHH.pop.logit1)
```

# Conclusion

Retrospectively, it is quite 
